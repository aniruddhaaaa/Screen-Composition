{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python Pillow torch transformers segment-anything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "from PIL import Image\n",
    "\n",
    "# Task 1: Segment Object Based on Text Prompt\n",
    "def segment_object(image_path, class_prompt, output_path):\n",
    "    # Load the SAM model\n",
    "    sam = sam_model_registry[\"vit_h\"](checkpoint=\"sam_vit_h_4b8939.pth\")\n",
    "    sam.to(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Use SAM to generate mask for the prompt\n",
    "    mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "    masks = mask_generator.generate(image_rgb)\n",
    "\n",
    "    # Here, we assume the first mask corresponds to the object of interest.\n",
    "    mask = masks[0]['segmentation']\n",
    "\n",
    "    # Create a red mask and apply it where the object is detected\n",
    "    red_mask = np.zeros_like(image)\n",
    "    red_mask[mask] = [0, 0, 255]  # Red color in BGR format\n",
    "\n",
    "    # Blend the red mask with the original image\n",
    "    result_image = cv2.addWeighted(image, 0.7, red_mask, 0.3, 0)\n",
    "\n",
    "    # Save the result\n",
    "    cv2.imwrite(output_path, result_image)\n",
    "    print(f\"Segmented image saved to {output_path}\")\n",
    "\n",
    "def move_object(image_path, class_prompt, shift_x, shift_y, output_path):\n",
    "    # Load the SAM model\n",
    "    sam = sam_model_registry[\"vit_h\"](checkpoint=\"sam_vit_h_4b8939.pth\")\n",
    "    sam.to(device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Use SAM to generate mask for the prompt\n",
    "    mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "    masks = mask_generator.generate(image_rgb)\n",
    "\n",
    "    # Get the mask of the object\n",
    "    mask = masks[0]['segmentation'].astype(np.uint8)  # Ensure mask is uint8\n",
    "\n",
    "    # Ensure mask is binary (0 or 255) for further operations\n",
    "    mask[mask > 0] = 255\n",
    "\n",
    "    # Extract the object using the binary mask\n",
    "    object_region = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Shift the object by x and y\n",
    "    rows, cols, _ = image.shape\n",
    "    translation_matrix = np.float32([[1, 0, shift_x], [0, 1, shift_y]])\n",
    "    shifted_object = cv2.warpAffine(object_region, translation_matrix, (cols, rows))\n",
    "\n",
    "    # Create an inverse mask to remove the object from the original location\n",
    "    inverse_mask = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Remove the object from the original image by applying the inverse mask\n",
    "    background = cv2.bitwise_and(image, image, mask=inverse_mask)\n",
    "\n",
    "    # Add the shifted object back to the image\n",
    "    result_image = cv2.add(background, shifted_object)\n",
    "\n",
    "    # Save the result\n",
    "    cv2.imwrite(output_path, result_image)\n",
    "    print(f\"Shifted object image saved to {output_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    task = \"segment\"  # or \"move\"\n",
    "    image_path = \"./bagpack.jpg\"  # Path to your uploaded image\n",
    "    class_prompt = \"bag\"  # Define the class prompt\n",
    "    output_path = \"./segmented_output.png\"  # Output path for the processed image\n",
    "    shift_x = 80  # Shift in x-direction for 'move' task\n",
    "    shift_y = 0  # Shift in y-direction for 'move' task\n",
    "\n",
    "    # Run the segment or move task\n",
    "    if task == \"segment\":\n",
    "        segment_object(image_path, class_prompt, output_path)\n",
    "    elif task == \"move\":\n",
    "        move_object(image_path, class_prompt, shift_x, shift_y, output_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
